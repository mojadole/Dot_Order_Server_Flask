{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스, 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음식 데이터 수 :  44\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_category</th>\n",
       "      <th>food_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>야채김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 당근, 오이, 우엉, 시금치, 단무지 같은 다양한 야채를 넣어서 만든 간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>치즈김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 치즈, 계란, 당근, 오이, 햄 등을 넣어서 만든 간단한 김밥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소고기김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 밥과 소고기, 단무지, 오이, 당근 같은 야채 등을 넣어서 만든 한국의 대표적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>매콤오징어김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>매콤한 양념으로 볶은 오징어와 오이, 당근, 단무지, 상추 같은 다양한 야채를 김에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>매콤땡초김밥</td>\n",
       "      <td>김밥</td>\n",
       "      <td>김에 잘게 다진 매콤한 땡초와 당근, 간장 양념과 비빈 밥과 햄 등을 넣어서 만든 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  food_name food_category                                   food_description\n",
       "0      야채김밥            김밥  김에 밥과 당근, 오이, 우엉, 시금치, 단무지 같은 다양한 야채를 넣어서 만든 간...\n",
       "1      치즈김밥            김밥           김에 밥과 치즈, 계란, 당근, 오이, 햄 등을 넣어서 만든 간단한 김밥\n",
       "2     소고기김밥            김밥  김에 밥과 소고기, 단무지, 오이, 당근 같은 야채 등을 넣어서 만든 한국의 대표적...\n",
       "3   매콤오징어김밥            김밥  매콤한 양념으로 볶은 오징어와 오이, 당근, 단무지, 상추 같은 다양한 야채를 김에...\n",
       "4    매콤땡초김밥            김밥  김에 잘게 다진 매콤한 땡초와 당근, 간장 양념과 비빈 밥과 햄 등을 넣어서 만든 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from key_extraction import keywordExtractor\n",
    "from transformers import ElectraModel, ElectraTokenizerFast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List, Dict\n",
    "from itertools import chain, islice\n",
    "import torch\n",
    "import openai\n",
    "from gensim.models import keyedvectors\n",
    "\n",
    "# load model and tokenizer\n",
    "name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model = ElectraModel.from_pretrained(name)\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(name)\n",
    "\n",
    "# load keywordExtractor\n",
    "key = keywordExtractor(model,tokenizer,dir='data/preprocess/eng_han.csv')\n",
    "\n",
    "# load food data\n",
    "#scraping_result = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "scraping_result = pd.read_csv('data/food_data2.csv')\n",
    "print('음식 데이터 수 : ', len(scraping_result))\n",
    "print('')\n",
    "scraping_result.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### 따로 만든 함수 #####################################\n",
    "API_KEY = 'sk-' ####### 키\n",
    "\n",
    "# chatGPT API 사용 함수\n",
    "def callChatGPT(prompt, API_KEY=API_KEY):\n",
    "    \n",
    "    messages = []\n",
    "\n",
    "    #get api key\n",
    "    openai.api_key = API_KEY\n",
    "\n",
    "    messages.append({\"role\":\"user\", \"content\":prompt})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\":\"assitant\", \"content\":chat_response})\n",
    "\n",
    "    return messages[1][\"content\"]\n",
    "\n",
    "# chatGPT한테 필요한 데이터 얻는 함수\n",
    "def obtain_data(menu_name):\n",
    "\n",
    "    #chat_res_cat = callChatGPT(menu_name + \" 는 [밥], [국], [면], [분식] 중에 뭐야\")\n",
    "    #chat_res_cat = chat_res_cat[chat_res_cat.find('[')+1:chat_res_cat.find(']')] # GPT 답변 : 메뉴 카테고리\n",
    "\n",
    "    #chat_res_des = callChatGPT(menu_name + \"한줄 설명\") # GPT 답변 : 메뉴 설명\n",
    "\n",
    "    menu_name = \"라면\"\n",
    "    chat_res_cat = \"면\"\n",
    "    chat_res_des = '라면은 말이죠'\n",
    "\n",
    "    #menu_str = menu_name + \" \" + chat_res_cat + \" \" + chat_res_des\n",
    "    menu_str = menu_name + \" \" + chat_res_des\n",
    "    menu_list = menu_str.split()\n",
    "\n",
    "    return menu_list\n",
    "\n",
    "# 새로운 메뉴명 -> 메뉴명, 카테고리, 메뉴설명 -> 키워드 리스트\n",
    "def get_keyword_list(menu_name):\n",
    "    min_count = 2\n",
    "    min_length = 1\n",
    "\n",
    "    raw_data = obtain_data(menu_name) # \n",
    "    keyword_list = key._extract_keywords(raw_data)\n",
    "    translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "    refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "    result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "    return (result)\n",
    "\n",
    "# 인덱스 번호 -> 기존 메뉴들 키워드 리스트 가져오기 (지금은 사용 X)\n",
    "def get_keyword_idx(num):\n",
    "    min_count = 2\n",
    "    min_length = 1\n",
    "\n",
    "    doc = scraping_result.iloc[num]\n",
    "  \n",
    "    raw_data = _convert_series_to_list_in_main(doc)\n",
    "    keyword_list = key._extract_keywords(raw_data)\n",
    "    translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "    refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "    result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "    return (result)\n",
    "\n",
    "# 기존 메뉴들의 food_name과 각 메뉴들에서 추출한 키워드 뽑아서 초기화하는 함수\n",
    "def init_function():\n",
    "    food_name = []\n",
    "    food_keyword = []\n",
    "\n",
    "    for i in range(len(scraping_result)):\n",
    "        docs_keywords = extract_keyword_in_main(scraping_result.iloc[[i]])\n",
    "        food_name.append(docs_keywords[\"food_name\"][0])\n",
    "        food_keyword.append(docs_keywords[\"keywords\"][0])\n",
    "\n",
    "    return [food_name, food_keyword]\n",
    "\n",
    "# 메뉴 검색하는 함수\n",
    "def search_menu(menu_name, food_name_list, food_keyword_list):\n",
    "    search = get_keyword_list(menu_name) # 입력된 메뉴에서 키워드 추출\n",
    "\n",
    "    w2v_model = keyedvectors.load_word2vec_format('data/w2v2')\n",
    "\n",
    "    # 키워드 확장 \n",
    "    recommand_keyword = w2v_model.most_similar(positive=search, topn=15)\n",
    "    np_recommand_keyword = np.array(list(map(lambda x: x[0], recommand_keyword)))\n",
    "    print('W2V을 활용한 키워드 확장 :', np_recommand_keyword)\n",
    "    print('')\n",
    "\n",
    "    # 키워드와 유사한 도서 검색 \n",
    "\n",
    "    user_point = [int(0)] * len(food_name_list)\n",
    "\n",
    "    for search_key in search:\n",
    "        for i in range(len(food_name_list)):\n",
    "            if search_key in food_keyword_list[i]:\n",
    "                user_point[i] = user_point[i] + int(1)\n",
    "\n",
    "\n",
    "    recommand_point = [int(0)] * len(food_name_list)\n",
    "\n",
    "    for search_key in np_recommand_keyword:\n",
    "        for i in range(len(food_name_list)):\n",
    "            \n",
    "            if search_key in food_keyword_list[i]:\n",
    "                recommand_point[i] = recommand_point[i] + int(1)\n",
    "\n",
    "    total_point = [int(0)] * len(user_point)\n",
    "    for i in range(len(user_point)):\n",
    "        total_point[i] = (user_point[i] * 3) + recommand_point[i]\n",
    "\n",
    "    top_k_idx = np.argsort(total_point)[::-1][:20]\n",
    "\n",
    "    # 메뉴명 연관 점수 저장\n",
    "    food_name_list = np.array(food_name_list)\n",
    "    total_point = np.array(total_point)\n",
    "\n",
    "    result  = dict(zip(food_name_list[top_k_idx], total_point[top_k_idx]))\n",
    "\n",
    "    # 음식 정보 추출\n",
    "    food_info = pd.read_csv('data/food_data.csv',encoding='cp949')\n",
    "    IDX = food_info.food_name.isin(list(result.keys()))\n",
    "\n",
    "    food_recommandation_result = food_info[[\"food_name\", \"food_category\"]][IDX].sort_values(\n",
    "        by=\"food_name\", key=lambda x: x.map(result), ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return list(food_recommandation_result.food_name)\n",
    "\n",
    "\n",
    "##################################### 기존 함수 수정한 함수 #####################################\n",
    "\n",
    "def extract_keyword_list_in_main(doc: pd.Series, min_count: int = 2, min_length: int = 2) -> List:\n",
    "\n",
    "\traw_data = _convert_series_to_list_in_main(doc)\n",
    "\tkeyword_list = key._extract_keywords(raw_data)\n",
    "\ttranslated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "\trefined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "\treturn list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "\n",
    "def _convert_series_to_list_in_main(series: pd.Series) -> List[List[str]]:\n",
    "\n",
    "\traw_data = list(series.values)\n",
    "\treturn list(chain(*map(lambda x: x.split(), raw_data)))\n",
    "\n",
    "def create_keyword_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tkeyword_list = extract_keyword_list_in_main(doc)\n",
    "\ttokenized_keyword = key.tokenize_keyword(keyword_list)\n",
    "\treturn key._create_keyword_embedding(tokenized_keyword)\n",
    "\n",
    "def create_doc_embedding_in_main(doc: pd.Series) -> torch.Tensor:\n",
    "\n",
    "\tstringified_doc = _convert_series_to_str_in_main(doc)\n",
    "\ttokenized_doc = key.tokenize_keyword(stringified_doc)\n",
    "\treturn key._create_doc_embedding(tokenized_doc)\n",
    "\n",
    "def _convert_series_to_str_in_main(series: pd.Series) -> str:\n",
    "\treturn \" \".join(list(series.values))\n",
    "\n",
    "def extract_keyword_in_main(docs: pd.DataFrame) -> Dict:\n",
    "\n",
    "\tkeyword_embedding = map(lambda x: create_keyword_embedding_in_main(x[1]), docs.iterrows())\n",
    "\tdoc_embedding = map(lambda x: create_doc_embedding_in_main(x[1]), docs.iterrows())\n",
    "\tkeyword_list = map(lambda x: extract_keyword_list_in_main(x[1]), docs.iterrows())\n",
    "\n",
    "\tco_sim_score = map(\n",
    "\t\tlambda x: key._calc_cosine_similarity(*x).flatten(),\n",
    "\t\tzip(doc_embedding, keyword_embedding),\n",
    "\t)\n",
    "\ttop_n_keyword = list(\n",
    "\t\tmap(lambda x: key._filter_top_n_keyword(*x), zip(keyword_list, co_sim_score))\n",
    "\t)\n",
    "\n",
    "\treturn dict(food_name=docs[\"food_name\"].tolist(), keywords=top_n_keyword)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작 : 메뉴 입력 + 전체 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "키워드에 따른 상위 20개 음식 추천 결과\n",
      "\n",
      "['떡라면', '콩나물라면', '매콤오징어김밥', '꽁치김치찌개', '참치볶음밥', '카레덮밥', '김치볶음밥', '뚝배기불고기', '육개장', '고등어김치찌개', '참치마요김밥', '참치김치찌개', '순두부찌개', '돼지김치찌개', '된장찌개', '어린이김밥', '새우날치알김밥', '참치와사비김밥', '수제왕돈까스']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if menu_name in food_name:\\n    print(\"일치하는 메뉴가 있습니다.\")\\n    lst.append(menu_name)\\n\\nelse :\\n    lst = search_menu(menu_name, food_name, food_keyword)\\n\\nif len(lst) == 0:\\n    print(\"해당 메뉴가 없습니다.\")\\nelse:\\n    print(lst)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_name = \"라면\" ## 입력\n",
    "\n",
    "lst = []\n",
    "food_name_list, food_keyword_list = init_function() #\n",
    "\n",
    "print('\\n\\n\\n키워드에 따른 상위 20개 음식 추천 결과\\n')\n",
    "print(search_menu(menu_name, food_name_list, food_keyword_list))\n",
    "\n",
    "\"\"\"if menu_name in food_name:\n",
    "    print(\"일치하는 메뉴가 있습니다.\")\n",
    "    lst.append(menu_name)\n",
    "\n",
    "else :\n",
    "    lst = search_menu(menu_name, food_name, food_keyword)\n",
    "\n",
    "if len(lst) == 0:\n",
    "    print(\"해당 메뉴가 없습니다.\")\n",
    "else:\n",
    "    print(lst)\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 추출 과정\n",
    "\n",
    "1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 음식 정보를 list로 통합 -> 12 개 단어\n",
      "['야채김밥', '김밥', '김에', '밥과', '다양한', '야채를', '넣어서', '만든', '한국의', '전통적인'].... \n",
      "\n",
      "2. 형태소 분석기를 활용해 명사만을 추출 -> 10 개 단어\n",
      "['야채', '김밥', '김밥', '김', '밥', '다양', '야채', '한국', '전통', '김밥'].... \n",
      "\n",
      "3. 영단어를 한글로 변환(ex python -> 파이썬) -> 10 개 단어\n",
      "['야채', '김밥', '김밥', '김', '밥', '다양', '야채', '한국', '전통', '김밥'].... \n",
      "\n",
      "4. 최소 2번이상 반복 사용되는 단어만 추출 -> 2 개 단어\n",
      "['야채', '김밥'].... \n",
      "\n",
      "5. 단어 길이가 최소 한개 이상인 단어만 추출 -> 2 개 단어\n",
      "['야채', '김밥'].... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_count = 2\n",
    "min_length = 1\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "#print(f'음식 정보 \\n \\n {doc} \\n \\n')\n",
    "\n",
    "## raw_data = key._convert_series_to_list(doc)\n",
    "raw_data = _convert_series_to_list_in_main(doc)\n",
    "\n",
    "print(f'\\n1. 음식 정보를 list로 통합 -> {len(raw_data)} 개 단어')\n",
    "print(f'{raw_data[:10]}.... \\n')\n",
    "\n",
    "keyword_list = key._extract_keywords(raw_data)\n",
    "print(f'2. 형태소 분석기를 활용해 명사만을 추출 -> {len(keyword_list)} 개 단어')\n",
    "print(f'{keyword_list[:10]}.... \\n')\n",
    "\n",
    "translated_keyword_list = key._map_english_to_korean(keyword_list)\n",
    "print(f'3. 영단어를 한글로 변환(ex python -> 파이썬) -> {len(translated_keyword_list)} 개 단어')\n",
    "print(f'{translated_keyword_list[:10]}.... \\n')\n",
    "\n",
    "refined_keyword_list = key._eliminate_min_count_words(translated_keyword_list, min_count)\n",
    "print(f'4. 최소 2번이상 반복 사용되는 단어만 추출 -> {len(refined_keyword_list)} 개 단어')\n",
    "print(f'{refined_keyword_list[:10]}.... \\n')\n",
    "\n",
    "result = list(filter(lambda x: len(x) >= min_length, refined_keyword_list))\n",
    "print(f'5. 단어 길이가 최소 한개 이상인 단어만 추출 -> {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 키워드 뽑기 + 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 메뉴명 -- \n",
      " 야채김밥 \n",
      " \n",
      "\n",
      "음식에 대한 키워드 후보 : 2 개 단어\n",
      "['야채', '김밥'].... \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "doc = scraping_result.iloc[0]\n",
    "\n",
    "print(f'-- 메뉴명 -- \\n {doc.food_name} \\n \\n')\n",
    "\n",
    "keyword_list = extract_keyword_list_in_main(doc)\n",
    "print(f'음식에 대한 키워드 후보 : {len(result)} 개 단어')\n",
    "print(f'{result[:10]}.... \\n \\n')\n",
    "\n",
    "keyword_embedding = create_keyword_embedding_in_main(doc)\n",
    "doc_embedding = create_doc_embedding_in_main(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 코사인 유사도순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 키워드 추출 결과(20개 요약)--\n",
      "[('야채', 0.85827744), ('김밥', 0.8466986)]\n"
     ]
    }
   ],
   "source": [
    "co_sim_score = key._calc_cosine_similarity(doc_embedding, keyword_embedding).flatten()\n",
    "\n",
    "keyword = dict(zip(keyword_list, co_sim_score))\n",
    "\n",
    "sorted_keyword = sorted(keyword.items(), key=lambda k: k[1], reverse=True)\n",
    "\n",
    "print(f'-- 키워드 추출 결과(20개 요약)--')\n",
    "pprint(sorted_keyword[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드 추출 예시\n",
      "\n",
      "메뉴명 :  야채김밥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>야채</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>김밥</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  야채\n",
       "1  김밥"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract keywords\n",
    "docs_keywords = extract_keyword_in_main(scraping_result.iloc[[0]])\n",
    "\n",
    "# result\n",
    "result = pd.DataFrame(docs_keywords)\n",
    "\n",
    "print('키워드 추출 예시\\n')\n",
    "print('메뉴명 : ', scraping_result.iloc[0].food_name)\n",
    "pd.DataFrame(result.keywords.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
